{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, Lipinski, Fragments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import DataPreprocessing as dprep\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = 'training_smiles.csv'\n",
    "test_data_path = 'test_smiles.csv'\n",
    "\n",
    "training_data = pd.read_csv(training_data_path, dtype = {'ACTIVE': int})\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:47:46] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "def extract_fingerprints(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Try nBits 2048, 1024, 512, 256\n",
    "    # Morgan Fingerprint\n",
    "    morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512)\n",
    "    for i in range(512):\n",
    "        features[f'fp_{i}'] = morgan_fp[i]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "    \n",
    "training_features_df = training_data['SMILES'].apply(extract_fingerprints)\n",
    "\n",
    "training_features_df = training_features_df.apply(pd.Series)\n",
    "\n",
    "training_data_fingerprint = training_data.join(training_features_df)\n",
    "\n",
    "training_data_fingerprint.to_csv('training_data_fingerprint.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:30:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:30:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:30:17] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_features(smiles):\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Basic Properties\n",
    "    features['num_atoms'] = mol.GetNumAtoms()\n",
    "    features['num_bonds'] = mol.GetNumBonds()\n",
    "    features['num_rings'] = mol.GetRingInfo().NumRings()\n",
    "\n",
    "    # Molecular Descriptors\n",
    "    for desc_name, desc_func in Descriptors.descList:\n",
    "        features[desc_name] = desc_func(mol)\n",
    "\n",
    "    # Lipinski Descriptors\n",
    "    features['num_rotatable_bonds'] = Lipinski.NumRotatableBonds(mol)\n",
    "    features['num_aromatic_rings'] = Lipinski.NumAromaticRings(mol)\n",
    "    features['num_heteroatoms'] = Lipinski.NumHeteroatoms(mol)\n",
    "    features['num_heavy_atoms'] = Lipinski.HeavyAtomCount(mol)\n",
    "    features['num_h_donors'] = Lipinski.NumHDonors(mol)\n",
    "    features['num_h_acceptors'] = Lipinski.NumHAcceptors(mol)\n",
    "    features['num_aliphatic_rings'] = Lipinski.NumAliphaticRings(mol)\n",
    "    features['num_saturated_rings'] = Lipinski.NumSaturatedRings(mol)\n",
    "    features['num_aromatic_heterocycles'] = Lipinski.NumAromaticHeterocycles(mol)\n",
    "    features['num_aromatic_carbocycles'] = Lipinski.NumAromaticCarbocycles(mol)\n",
    "    features['num_aliphatic_heterocycles'] = Lipinski.NumAliphaticHeterocycles(mol)\n",
    "    features['num_aliphatic_carbocycles'] = Lipinski.NumAliphaticCarbocycles(mol)\n",
    "\n",
    "    # Fragment Descriptors\n",
    "    for frag_func in dir(Fragments):\n",
    "        if frag_func.startswith('fr_'):\n",
    "            features[frag_func] = getattr(Fragments, frag_func)(mol)\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "training_features_df = training_data['SMILES'].apply(extract_features)\n",
    "\n",
    "training_features_df = training_features_df.apply(pd.Series)\n",
    "\n",
    "training_data_features = training_data.join(training_features_df)\n",
    "\n",
    "training_data_features.to_csv('training_data_features.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "fingerprint_df = pd.read_csv('training_data_fingerprint.csv')\n",
    "other_features_df = pd.read_csv('training_data_207_features.csv')\n",
    "\n",
    "# Combine datasets\n",
    "combined_df = pd.concat([fingerprint_df, other_features_df], axis=1)\n",
    "\n",
    "#combined_df, column_filter = dprep.create_column_filter(combined_df)\n",
    "#combined_df, imputation = dprep.create_imputation(combined_df)\n",
    "\n",
    "\n",
    "# Select only numeric columns for imputation\n",
    "numeric_cols = combined_df.select_dtypes(include=[np.number]).columns\n",
    "numeric_df = combined_df[numeric_cols]\n",
    "\n",
    "simple_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "numeric_df_imputed = pd.DataFrame(simple_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "\n",
    "\n",
    "training_data = pd.concat([combined_df.drop(columns=numeric_cols), numeric_df_imputed], axis=1)\n",
    "\n",
    "\n",
    "X = training_data.drop(columns=[\"INDEX\", \"SMILES\", \"ACTIVE\"])\n",
    "y = training_data[\"ACTIVE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = combined_df['ACTIVE'].iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Importance\n",
      "537       BCUT2D_MRLOW    0.009652\n",
      "512  MaxAbsEStateIndex    0.008942\n",
      "514  MinAbsEStateIndex    0.008766\n",
      "515     MinEStateIndex    0.008634\n",
      "513     MaxEStateIndex    0.008383\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_clf.fit(X, y)\n",
    "\n",
    "importances = rf_clf.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df.to_csv('feature_importances.csv', index=False)\n",
    "\n",
    "print(feature_importance_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_on_folds(X, y, classifier, use_smote=False, print_results=False, number_of_folds=5):\n",
    "\n",
    "    # Apply SMOTE if required\n",
    "    if use_smote:\n",
    "        smote = SMOTE()\n",
    "        X, y = smote.fit_resample(X, y)\n",
    "\n",
    "    # Perform n-fold cross-validation\n",
    "    y_proba = cross_val_predict(classifier, X, y, cv=number_of_folds, method='predict_proba')\n",
    "    y_pred = np.argmax(y_proba, axis=1)\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    class_report = classification_report(y, y_pred)\n",
    "    auc_roc = roc_auc_score(y, y_proba[:, 1])\n",
    "\n",
    "    if print_results:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(class_report)\n",
    "        print(\"\\nAUC-ROC Score:\", auc_roc)\n",
    "\n",
    "    return conf_matrix, class_report, auc_roc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "num_features_list = [10, 30, 50, 80, 100, len(X.columns)]\n",
    "feature_importances = pd.read_csv('feature_importances.csv')\n",
    "\n",
    "results_without_SMOTE = {}\n",
    "results_with_SMOTE = {}\n",
    "\n",
    "def evaluate_model(X, y, classifier, num_features_list, use_smote):\n",
    "    results = {}\n",
    "    all_feature_names = X.columns.tolist()\n",
    "\n",
    "    for num_features in num_features_list:\n",
    "        n_best_features = feature_importances['Feature'].head(num_features).tolist()\n",
    "        valid_features = [f for f in n_best_features if f in all_feature_names]\n",
    "\n",
    "        # Call test_model_on_folds with valid features\n",
    "        X_subset = X[valid_features]\n",
    "        conf_matrix, class_report, auc_roc = test_model_on_folds(X_subset, y, classifier, use_smote=use_smote, print_results=True)\n",
    "        results[str(num_features)] = [auc_roc]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[151414     32]\n",
      " [  1742     42]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.57      0.02      0.05      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.78      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7166547867940201\n",
      "Confusion Matrix:\n",
      "[[151426     20]\n",
      " [  1743     41]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.67      0.02      0.04      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.83      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7661129132946143\n",
      "Confusion Matrix:\n",
      "[[151426     20]\n",
      " [  1743     41]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.67      0.02      0.04      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.83      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7474635026565138\n",
      "Confusion Matrix:\n",
      "[[151424     22]\n",
      " [  1747     37]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.63      0.02      0.04      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.81      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7396388963604603\n",
      "Confusion Matrix:\n",
      "[[151418     28]\n",
      " [  1740     44]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.61      0.02      0.05      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.80      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7495741056218057\n",
      "Confusion Matrix:\n",
      "[[151426     20]\n",
      " [  1736     48]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.71      0.03      0.05      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.85      0.51      0.52    153230\n",
      "weighted avg       0.99      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7710746634876264\n",
      "Results without SMOTE\n",
      "10 : [0.7166547867940201]\n",
      "30 : [0.7661129132946143]\n",
      "50 : [0.7474635026565138]\n",
      "80 : [0.7396388963604603]\n",
      "100 : [0.7495741056218057]\n",
      "722 : [0.7710746634876264]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate without SMOTE\n",
    "results_without_SMOTE = evaluate_model(X, y, rf_clf, num_features_list, use_smote=False)\n",
    "\n",
    "print(\"Results without SMOTE\")\n",
    "for key, value in results_without_SMOTE.items():\n",
    "    print(key, \":\", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[149605   1841]\n",
      " [  1138 150308]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    151446\n",
      "           1       0.99      0.99      0.99    151446\n",
      "\n",
      "    accuracy                           0.99    302892\n",
      "   macro avg       0.99      0.99      0.99    302892\n",
      "weighted avg       0.99      0.99      0.99    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9993570208781507\n",
      "Confusion Matrix:\n",
      "[[150762    684]\n",
      " [   468 150978]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    151446\n",
      "           1       1.00      1.00      1.00    151446\n",
      "\n",
      "    accuracy                           1.00    302892\n",
      "   macro avg       1.00      1.00      1.00    302892\n",
      "weighted avg       1.00      1.00      1.00    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9998507236534854\n",
      "Confusion Matrix:\n",
      "[[151051    395]\n",
      " [   298 151148]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    151446\n",
      "           1       1.00      1.00      1.00    151446\n",
      "\n",
      "    accuracy                           1.00    302892\n",
      "   macro avg       1.00      1.00      1.00    302892\n",
      "weighted avg       1.00      1.00      1.00    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9999233155578546\n",
      "Confusion Matrix:\n",
      "[[151331    115]\n",
      " [  1074 150372]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    151446\n",
      "           1       1.00      0.99      1.00    151446\n",
      "\n",
      "    accuracy                           1.00    302892\n",
      "   macro avg       1.00      1.00      1.00    302892\n",
      "weighted avg       1.00      1.00      1.00    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9998486915327287\n",
      "Confusion Matrix:\n",
      "[[151358     88]\n",
      " [  1494 149952]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       1.00      0.99      0.99    151446\n",
      "\n",
      "    accuracy                           0.99    302892\n",
      "   macro avg       0.99      0.99      0.99    302892\n",
      "weighted avg       0.99      0.99      0.99    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9996332160354786\n",
      "Confusion Matrix:\n",
      "[[151417     29]\n",
      " [  1738 149708]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       1.00      0.99      0.99    151446\n",
      "\n",
      "    accuracy                           0.99    302892\n",
      "   macro avg       0.99      0.99      0.99    302892\n",
      "weighted avg       0.99      0.99      0.99    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9986567928138119\n",
      "\n",
      "Results with SMOTE\n",
      "10 : [0.9993570208781507]\n",
      "30 : [0.9998507236534854]\n",
      "50 : [0.9999233155578546]\n",
      "80 : [0.9998486915327287]\n",
      "100 : [0.9996332160354786]\n",
      "722 : [0.9986567928138119]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with SMOTE\n",
    "results_with_SMOTE = evaluate_model(X, y, rf_clf, num_features_list, use_smote=True)\n",
    "\n",
    "print(\"\\nResults with SMOTE\")\n",
    "for key, value in results_with_SMOTE.items():\n",
    "    print(key, \":\", value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
