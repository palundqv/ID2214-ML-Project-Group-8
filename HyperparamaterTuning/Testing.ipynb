{"cells":[{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def create_imputation(df):\n","    df_copy = df.copy()\n","    imputation = {}\n","\n","    # Handle numeric columns\n","    for column in df_copy.select_dtypes(include=['int', 'float']).columns:\n","        if column not in ['CLASS', 'ID']:\n","            if df_copy[column].isnull().all():\n","                imputation[column] = 0\n","            else:\n","                mean_value = df_copy[column].mean()\n","                df_copy[column].fillna(mean_value, inplace=True)\n","                imputation[column] = mean_value\n","\n","    # Handle categorical and object columns\n","    for column in df_copy.select_dtypes(include=['object', 'category']).columns:\n","        if column not in ['CLASS', 'ID']:\n","            if df_copy[column].isnull().all():\n","                if is_categorical_dtype(df_copy[column]):\n","                    imputation[column] = df_copy[column].cat.categories[0]\n","                else:\n","                    imputation[column] = \"\"\n","            else:\n","                mode_value = df_copy[column].mode()[0]\n","                df_copy[column].fillna(mode_value, inplace=True)\n","                imputation[column] = mode_value\n","\n","    return df_copy, imputation\n","\n","def apply_imputation(df, imputation):\n","    df_copy = df.copy()\n","\n","    for column, value in imputation.items():\n","        df_copy[column].fillna(value, inplace=True)\n","\n","    return df_copy"]},{"cell_type":"code","execution_count":22,"metadata":{"cell_id":"192950fa2ac646adb2bc239c17ca0eba","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2003,"execution_start":1701812622630,"source_hash":null},"outputs":[],"source":["# Import necessary libraries\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","def test_hyperparameter_all_models_random_search(X, y, test_size=0.3):\n","    \n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n","\n","    # Define a list of models to test\n","    models = [\n","        (\"Linear Regression\", LinearRegression()),\n","        (\"Random Forest\", RandomForestClassifier()),\n","        (\"Support Vector Machine\", SVC()),\n","        (\"K-Nearest Neighbors\", KNeighborsClassifier()),\n","        (\"Gaussian Naive Bayes\", GaussianNB()),\n","        (\"Multi-layer Perceptron\", MLPClassifier(max_iter=1000)),\n","    ]\n","\n","    # Results storage\n","    results = []\n","\n","    # Hyperparameter search for each model\n","    for model_name, model in models:\n","        if model_name == \"Random Forest\":\n","            param_grid = {\n","                'n_estimators': [10, 50, 100, 200],\n","                'max_depth': [None, 10, 20, 30],\n","                'min_samples_split': [2, 5, 10],\n","                'min_samples_leaf': [1, 2, 4],\n","                'bootstrap': [True, False],\n","            }\n","        elif model_name == \"Support Vector Machine\":\n","            param_grid = {\n","                'C': [0.1, 1, 10, 100],\n","                'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n","                'gamma': ['scale', 'auto'],\n","            }\n","        elif model_name == \"K-Nearest Neighbors\":\n","            param_grid = {\n","                'n_neighbors': [3, 5, 7, 10],\n","                'weights': ['uniform', 'distance'],\n","                'p': [1, 2],\n","            }\n","        elif model_name == \"Multi-layer Perceptron\":\n","            param_grid = {\n","                'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n","                'activation': ['relu', 'tanh'],\n","                'alpha': [0.0001, 0.001, 0.01],\n","            }\n","        else:\n","            print(f\"Unsupported model: {model_name}\")\n","            continue\n","\n","        # Randomized search for hyperparameter tuning using training and validation sets\n","        random_search = RandomizedSearchCV(model, param_grid, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n","\n","        # Train the model on the combined training and validation sets\n","        random_search.fit(X_train, y_train)\n","\n","        # Get the best model from the search\n","        best_model = random_search.best_estimator_\n","\n","        # Make predictions on the test set\n","        y_pred = best_model.predict(X_test)\n","\n","        # Evaluate the model on the test set and store accuracy\n","        accuracy = accuracy_score(y_test, y_pred)\n","\n","        # Print the results\n","        print(f\"\\n{model_name} Best Parameters: {random_search.best_params_}\")\n","        print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n","\n","        # Store results\n","        results.append({\n","            'Model': model_name,\n","            'Accuracy': accuracy,\n","        })\n","\n","    # Create a bar plot for accuracy\n","    models_names = [result['Model'] for result in results]\n","    accuracies = [result['Accuracy'] for result in results]\n","    plt.figure(figsize=(10, 6))\n","    plt.bar(models_names, accuracies, color='blue', alpha=0.7)\n","    plt.xlabel('Model')\n","    plt.ylabel('Accuracy')\n","    plt.title('Accuracy for Different Models')\n","    plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3129096e-2078-4742-bd9d-c05dc1a0bf39' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Random Forest Best Parameters: {'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': True}\n","Random Forest Accuracy: 1.0000\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\patah\\Documents\\ID2214-ML-Project-Group-8\\Testing.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m traning_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mtraining_smiles.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y \u001b[39m=\u001b[39m traning_data[\u001b[39m\"\u001b[39m\u001b[39mACTIVE\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_hyperparameter_all_models_random_search(X_imputed, y)\n","\u001b[1;32mc:\\Users\\patah\\Documents\\ID2214-ML-Project-Group-8\\Testing.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m grid_search \u001b[39m=\u001b[39m RandomizedSearchCV(model, param_grid, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# Train the model on the combined training and validation sets\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49mconcatenate((X_train, X_validation)), np\u001b[39m.\u001b[39;49mconcatenate((y_train, y_validation)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39m# Get the best model from the search\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/patah/Documents/ID2214-ML-Project-Group-8/Testing.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m best_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1808\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1809\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1810\u001b[0m         ParameterSampler(\n\u001b[0;32m   1811\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1812\u001b[0m         )\n\u001b[0;32m   1813\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\patah\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.impute import SimpleImputer\n","\n","x = pd.read_csv(\"training_with_207_features.csv\")\n","x.drop(columns=\"SMILES\", inplace=True)\n","imputer = SimpleImputer(strategy='mean')\n","X_imputed = imputer.fit_transform(x)\n","traning_data = pd.read_csv(\"training_smiles.csv\")\n","y = traning_data[\"ACTIVE\"].astype(\"category\")\n","\n","test_hyperparameter_all_models_random_search(X_imputed, y)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["from skopt import BayesSearchCV\n","\n","def find_hyperparameters_bayes_optimization(X, y, test_size=0.2):\n","    # Split the dataset into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n","\n","    # Define hyperparameter search spaces for each algorithm\n","    models = {\n","        # 'Random Forest': (RandomForestClassifier(), \n","        #                   {'n_estimators': (10, 200), \n","        #                    'max_depth': (1, 20),\n","        #                    'min_samples_split': (2, 10),\n","        #                    'min_samples_leaf': (1, 10)}),\n","        'Support Vector Machine': (SVC(), \n","                                   {'C': (1e-6, 1e+6, \n","                                    'log-uniform'),\n","                                    'gamma': (1e-6, 1e+1,\n","                                    'log-uniform')}),\n","        'K-Nearest Neighbors': (KNeighborsClassifier(), \n","                                {'n_neighbors': (1, 10), \n","                                 'weights': ['uniform', 'distance']}),\n","        'Multi-layer Perceptron': (MLPClassifier(), \n","                                   {'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50, 25)], \n","                                    'activation': ['relu', 'tanh'], \n","                                    'alpha': (1e-6, 1e-2, 'log-uniform')}),\n","    }\n","\n","    best_hyperparameters = {}\n","\n","    for model_name, (model, params) in models.items():\n","        # Perform Bayesian optimization for each algorithm\n","        opt = BayesSearchCV(model, params, n_iter=50, cv=5)\n","        opt.fit(X_train, y_train)\n","\n","        # Evaluate on the test set and calculate accuracy\n","        accuracy = opt.score(X_test, y_test)\n","\n","        # Save the best hyperparameters and test accuracy for each algorithm\n","        best_hyperparameters[model_name] = {'params': opt.best_params_, 'accuracy': accuracy}\n","\n","        # Print the results for each model\n","        print(f\"{model_name} - Best Hyperparameters: {opt.best_params_}, Accuracy: {accuracy}\")\n","\n","    return best_hyperparameters\n","\n","# Example usage:\n","# best_hyperparameters = find_hyperparameters_bayes_optimization(X, y)\n","# print(best_hyperparameters)\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["\n","x_imp, imputation = create_imputation(x)\n","\n","find_hyperparameters_bayes_optimization(x_imp, y)"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"0cdef4d1df3b45978548b6ad475bbfce","deepnote_persisted_session":{"createdAt":"2023-12-05T22:04:07.783Z"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
