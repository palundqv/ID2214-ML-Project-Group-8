{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, Lipinski, Fragments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, accuracy_score\n",
    "import DataPreprocessing as dprep\n",
    "from sklearn.impute import SimpleImputer\n",
    "import DescriptionFeaturesSelection as dsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = 'training_smiles.csv'\n",
    "test_data_path = 'test_smiles.csv'\n",
    "\n",
    "training_data = pd.read_csv(training_data_path, dtype = {'ACTIVE': int})\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:47:46] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "def extract_fingerprints(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Try nBits 2048, 1024, 512, 256\n",
    "    # Morgan Fingerprint\n",
    "    morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512)\n",
    "    for i in range(512):\n",
    "        features[f'fp_{i}'] = morgan_fp[i]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "    \n",
    "training_features_df = training_data['SMILES'].apply(extract_fingerprints)\n",
    "\n",
    "training_features_df = training_features_df.apply(pd.Series)\n",
    "\n",
    "training_data_fingerprint = training_data.join(training_features_df)\n",
    "\n",
    "training_data_fingerprint.to_csv('training_data_fingerprint.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:30:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:30:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:30:17] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_features(smiles):\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # Basic Properties\n",
    "    features['num_atoms'] = mol.GetNumAtoms()\n",
    "    features['num_bonds'] = mol.GetNumBonds()\n",
    "    features['num_rings'] = mol.GetRingInfo().NumRings()\n",
    "\n",
    "    # Molecular Descriptors\n",
    "    for desc_name, desc_func in Descriptors.descList:\n",
    "        features[desc_name] = desc_func(mol)\n",
    "\n",
    "    # Lipinski Descriptors\n",
    "    features['num_rotatable_bonds'] = Lipinski.NumRotatableBonds(mol)\n",
    "    features['num_aromatic_rings'] = Lipinski.NumAromaticRings(mol)\n",
    "    features['num_heteroatoms'] = Lipinski.NumHeteroatoms(mol)\n",
    "    features['num_heavy_atoms'] = Lipinski.HeavyAtomCount(mol)\n",
    "    features['num_h_donors'] = Lipinski.NumHDonors(mol)\n",
    "    features['num_h_acceptors'] = Lipinski.NumHAcceptors(mol)\n",
    "    features['num_aliphatic_rings'] = Lipinski.NumAliphaticRings(mol)\n",
    "    features['num_saturated_rings'] = Lipinski.NumSaturatedRings(mol)\n",
    "    features['num_aromatic_heterocycles'] = Lipinski.NumAromaticHeterocycles(mol)\n",
    "    features['num_aromatic_carbocycles'] = Lipinski.NumAromaticCarbocycles(mol)\n",
    "    features['num_aliphatic_heterocycles'] = Lipinski.NumAliphaticHeterocycles(mol)\n",
    "    features['num_aliphatic_carbocycles'] = Lipinski.NumAliphaticCarbocycles(mol)\n",
    "\n",
    "    # Fragment Descriptors\n",
    "    for frag_func in dir(Fragments):\n",
    "        if frag_func.startswith('fr_'):\n",
    "            features[frag_func] = getattr(Fragments, frag_func)(mol)\n",
    "\n",
    "\n",
    "    return features\n",
    "\n",
    "training_features_df = training_data['SMILES'].apply(extract_features)\n",
    "\n",
    "training_features_df = training_features_df.apply(pd.Series)\n",
    "\n",
    "training_data_features = training_data.join(training_features_df)\n",
    "\n",
    "training_data_features.to_csv('training_data_features.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Load the datasets\n",
    "fingerprint_df = pd.read_csv('training_data_fingerprint.csv')\n",
    "other_features_df = pd.read_csv('training_data_207_features.csv')\n",
    "\n",
    "# Combine datasets\n",
    "combined_df = pd.concat([fingerprint_df, other_features_df], axis=1) \"\"\"\n",
    "\n",
    "training_data = pd.read_csv('csvData/training_merged_fingerprints207.csv')\n",
    "\n",
    "training_data, column_filter = dprep.create_column_filter(training_data)\n",
    "training_data, imputation = dprep.create_imputation(training_data)\n",
    "\n",
    "\n",
    "# Select only numeric columns for imputation\n",
    "#numeric_cols = combined_df.select_dtypes(include=[np.number]).columns\n",
    "#numeric_df = combined_df[numeric_cols]\n",
    "\n",
    "#simple_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#numeric_df_imputed = pd.DataFrame(simple_imputer.fit_transform(numeric_df), columns=numeric_df.columns)\n",
    "\n",
    "\n",
    "#training_data = pd.concat([combined_df.drop(columns=numeric_cols), numeric_df_imputed], axis=1)\n",
    "\n",
    "\n",
    "X = training_data.drop(columns=[\"INDEX\", \"ACTIVE\"])\n",
    "y = training_data[\"ACTIVE\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature  Importance\n",
      "537       BCUT2D_MRLOW    0.009636\n",
      "512  MaxAbsEStateIndex    0.008735\n",
      "515     MinEStateIndex    0.008680\n",
      "514  MinAbsEStateIndex    0.008660\n",
      "513     MaxEStateIndex    0.008062\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_clf.fit(X, y)\n",
    "\n",
    "importances = rf_clf.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df.to_csv('feature_importances.csv', index=False)\n",
    "\n",
    "print(feature_importance_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_crossValidation(training, training_lables, number_of_features = 50, use_classifier=\"randomForest\", sampling=\"smote\"):\n",
    "    if use_classifier == \"randomForest\":\n",
    "        classifier = RandomForestClassifier(bootstrap=True, max_depth=40, min_samples_leaf=2,min_samples_split=2,n_estimators=200,class_weight=\"balanced\",random_state=42)\n",
    "    elif use_classifier == \"MLP\":\n",
    "        classifier = MLPClassifier(activation = 'relu',alpha= 0.0001, hidden_layer_sizes=(50,))\n",
    "    else:\n",
    "        print(\"Invalid classifier specified:\")\n",
    "        return\n",
    "    \n",
    "    X = training.copy()\n",
    "    y = training_lables.copy()\n",
    "\n",
    "    # Set up cross-validation\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "    auc_scores = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        n_best_features = dsf.select_n_best_features_randomForestImportance(X_train, y_train, n_features=number_of_features) ## should be moved into the fold calculation loop\n",
    "        X_train = X_train[list(n_best_features.keys())]\n",
    "        X_test = X_test[list(n_best_features.keys())]\n",
    "\n",
    "\n",
    "        if sampling==\"smote\":\n",
    "            # Apply SMOTE to the training set\n",
    "            smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "        elif sampling==\"under\":\n",
    "            X_train_resampled, y_train_resampled = new_balance_labels_down(X_train, y_train)\n",
    "        else:\n",
    "            X_train_resampled, y_train_resampled = X_train, y_train\n",
    "\n",
    "        classifier.fit(X_train_resampled, y_train_resampled)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc_score = roc_auc_score(y_test, classifier.predict_proba(X_test)[:, 1])\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        auc_scores.append(auc_score)\n",
    "        confusion_matrices.append(cm)\n",
    "\n",
    "    avg_auc_score = np.mean(auc_scores)\n",
    "    avg_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        'average_auc_score': avg_auc_score,\n",
    "        'confusion_matrix': avg_confusion_matrix,\n",
    "        'classification_report': class_report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_list = [10, 30, 50, 80, 100, len(X.columns)]\n",
    "\n",
    "for num_features in num_features_list:\n",
    "    ## Testing Random forest with and without smote\n",
    "    results_oversampled = manual_crossValidation(X, y, num_features,use_classifier='randomForest',sampling=\"smote\")\n",
    "    results_undersampled = manual_crossValidation(X, y, num_features,use_classifier='randomForest',sampling=\"under\")\n",
    "\n",
    "    print(\"Random-Forest with SMOTE: \", results_oversampled[\"average_auc_score\"])\n",
    "    print(\"Random-Forest no SMOTE: \", results_undersampled[\"average_auc_score\"])\n",
    "\n",
    "    ## Testing MLP with and without smote\n",
    "    MLP_results_oversampled = manual_crossValidation(training, training_lables, num_features,use_classifier='MLP', sampling=\"smote\")\n",
    "    MLP_results_undersampled = manual_crossValidation(training, training_lables, num_features, use_classifier='MLP',sampling=\"under\")\n",
    "\n",
    "    print(\"MLP with SMOTE: \", MLP_results_oversampled[\"average_auc_score\"])\n",
    "    print(\"MLP no SMOTE: \", MLP_results_undersampled[\"average_auc_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[151414     32]\n",
      " [  1742     42]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.57      0.02      0.05      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.78      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7166547867940201\n",
      "Confusion Matrix:\n",
      "[[151426     20]\n",
      " [  1743     41]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.67      0.02      0.04      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.83      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7661129132946143\n",
      "Confusion Matrix:\n",
      "[[151426     20]\n",
      " [  1743     41]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.67      0.02      0.04      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.83      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7474635026565138\n",
      "Confusion Matrix:\n",
      "[[151424     22]\n",
      " [  1747     37]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.63      0.02      0.04      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.81      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7396388963604603\n",
      "Confusion Matrix:\n",
      "[[151418     28]\n",
      " [  1740     44]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.61      0.02      0.05      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.80      0.51      0.52    153230\n",
      "weighted avg       0.98      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7495741056218057\n",
      "Confusion Matrix:\n",
      "[[151426     20]\n",
      " [  1736     48]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       0.71      0.03      0.05      1784\n",
      "\n",
      "    accuracy                           0.99    153230\n",
      "   macro avg       0.85      0.51      0.52    153230\n",
      "weighted avg       0.99      0.99      0.98    153230\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.7710746634876264\n",
      "Results without SMOTE\n",
      "10 : [0.7166547867940201]\n",
      "30 : [0.7661129132946143]\n",
      "50 : [0.7474635026565138]\n",
      "80 : [0.7396388963604603]\n",
      "100 : [0.7495741056218057]\n",
      "722 : [0.7710746634876264]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate without SMOTE\n",
    "results_without_SMOTE = evaluate_model(X, y, rf_clf, num_features_list, use_smote=False)\n",
    "\n",
    "print(\"Results without SMOTE\")\n",
    "for key, value in results_without_SMOTE.items():\n",
    "    print(key, \":\", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[149605   1841]\n",
      " [  1138 150308]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    151446\n",
      "           1       0.99      0.99      0.99    151446\n",
      "\n",
      "    accuracy                           0.99    302892\n",
      "   macro avg       0.99      0.99      0.99    302892\n",
      "weighted avg       0.99      0.99      0.99    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9993570208781507\n",
      "Confusion Matrix:\n",
      "[[150762    684]\n",
      " [   468 150978]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    151446\n",
      "           1       1.00      1.00      1.00    151446\n",
      "\n",
      "    accuracy                           1.00    302892\n",
      "   macro avg       1.00      1.00      1.00    302892\n",
      "weighted avg       1.00      1.00      1.00    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9998507236534854\n",
      "Confusion Matrix:\n",
      "[[151051    395]\n",
      " [   298 151148]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    151446\n",
      "           1       1.00      1.00      1.00    151446\n",
      "\n",
      "    accuracy                           1.00    302892\n",
      "   macro avg       1.00      1.00      1.00    302892\n",
      "weighted avg       1.00      1.00      1.00    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9999233155578546\n",
      "Confusion Matrix:\n",
      "[[151331    115]\n",
      " [  1074 150372]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    151446\n",
      "           1       1.00      0.99      1.00    151446\n",
      "\n",
      "    accuracy                           1.00    302892\n",
      "   macro avg       1.00      1.00      1.00    302892\n",
      "weighted avg       1.00      1.00      1.00    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9998486915327287\n",
      "Confusion Matrix:\n",
      "[[151358     88]\n",
      " [  1494 149952]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       1.00      0.99      0.99    151446\n",
      "\n",
      "    accuracy                           0.99    302892\n",
      "   macro avg       0.99      0.99      0.99    302892\n",
      "weighted avg       0.99      0.99      0.99    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9996332160354786\n",
      "Confusion Matrix:\n",
      "[[151417     29]\n",
      " [  1738 149708]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    151446\n",
      "           1       1.00      0.99      0.99    151446\n",
      "\n",
      "    accuracy                           0.99    302892\n",
      "   macro avg       0.99      0.99      0.99    302892\n",
      "weighted avg       0.99      0.99      0.99    302892\n",
      "\n",
      "\n",
      "AUC-ROC Score: 0.9986567928138119\n",
      "\n",
      "Results with SMOTE\n",
      "10 : [0.9993570208781507]\n",
      "30 : [0.9998507236534854]\n",
      "50 : [0.9999233155578546]\n",
      "80 : [0.9998486915327287]\n",
      "100 : [0.9996332160354786]\n",
      "722 : [0.9986567928138119]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with SMOTE\n",
    "results_with_SMOTE = evaluate_model(X, y, rf_clf, num_features_list, use_smote=True)\n",
    "\n",
    "print(\"\\nResults with SMOTE\")\n",
    "for key, value in results_with_SMOTE.items():\n",
    "    print(key, \":\", value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
